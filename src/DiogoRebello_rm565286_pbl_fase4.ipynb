{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb5199f",
   "metadata": {},
   "source": [
    "\n",
    "# FarmTech Solutions — Fase 5 (ML + Cloud)\n",
    "\n",
    "**Autor:** Diogo Rebello  \n",
    "\n",
    "**Notebook gerado:** 2025-09-01 04:14:33\n",
    "\n",
    "Este notebook cobre:\n",
    "- Análise exploratória (EDA)\n",
    "- Clusterização (KMeans + PCA 2D) e detecção de outliers (IsolationForest)\n",
    "- **5 modelos de regressão**: Regressão Linear, Árvore de Decisão, KNN, Floresta Aleatória, **XGBoost**\n",
    "- Comparação por **MAE, RMSE e R²**\n",
    "- Export do melhor modelo para `artifacts/best_model.joblib`\n",
    "\n",
    "> **Instruções:** Coloque o arquivo `crop_yield.csv` na mesma pasta do notebook ao executar localmente. Renomeie este arquivo para incluir seu RM antes de subir ao GitHub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347203de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Setup =====\n",
    "import os, math, joblib, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# clusterização\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "plt.ioff()  # evitar muitos popups\n",
    "\n",
    "ROOT = Path('.')\n",
    "FIG_DIR = ROOT / 'figures'\n",
    "ART_DIR = ROOT / 'artifacts'\n",
    "FIG_DIR.mkdir(exist_ok=True, parents=True)\n",
    "ART_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "CSV_PATH = ROOT / 'crop_yield.csv'\n",
    "assert CSV_PATH.exists(), f'CSV não encontrado em {CSV_PATH}'\n",
    "print('CSV:', CSV_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Carregar e padronizar colunas =====\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "rename_map = {\n",
    "    'Crop': 'crop',\n",
    "    'Precipitation (mm day-1)': 'precip_mm_day',\n",
    "    'Specific Humidity at 2 Meters (g/kg)': 'spec_humidity_gkg',\n",
    "    'Relative Humidity at 2 Meters (%)': 'rel_humidity_pct',\n",
    "    'Temperature at 2 Meters (C)': 'temp_c',\n",
    "    'Yield': 'yield_t_ha'\n",
    "}\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "num_cols = ['precip_mm_day', 'spec_humidity_gkg', 'rel_humidity_pct', 'temp_c']\n",
    "cat_cols = ['crop']\n",
    "target = 'yield_t_ha'\n",
    "\n",
    "display(df.head())\n",
    "print('Shape:', df.shape)\n",
    "print('Tipos:\\n', df.dtypes)\n",
    "print('Missing por coluna:\\n', df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7019051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== EDA =====\n",
    "# Histograma do target\n",
    "plt.figure()\n",
    "df[target].hist(bins=30)\n",
    "plt.title('Distribuição do Rendimento (t/ha)')\n",
    "plt.xlabel(target); plt.ylabel('freq')\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / 'hist_yield.png'); plt.show()\n",
    "\n",
    "# Dispersão temperatura x yield\n",
    "plt.figure()\n",
    "plt.scatter(df['temp_c'], df[target], s=10)\n",
    "plt.title('Temperatura vs Rendimento')\n",
    "plt.xlabel('temp_c'); plt.ylabel(target)\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / 'scatter_temp_yield.png'); plt.show()\n",
    "\n",
    "# Correlação numérica\n",
    "corr = df[num_cols + [target]].corr(numeric_only=True)\n",
    "plt.figure()\n",
    "plt.imshow(corr, interpolation='nearest')\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(len(corr.index)), corr.index)\n",
    "plt.colorbar()\n",
    "plt.title('Correlação (numéricas)')\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / 'corr_matrix.png'); plt.show()\n",
    "\n",
    "corr[target].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7423f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Clusterização (KMeans) + PCA 2D =====\n",
    "X_cluster = df[num_cols].copy().values\n",
    "X_scaled = StandardScaler().fit_transform(X_cluster)\n",
    "\n",
    "k_opts = [2,3,4]\n",
    "scores = []\n",
    "for k in k_opts:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    scores.append(silhouette_score(X_scaled, labels))\n",
    "\n",
    "best_k = int(k_opts[int(np.argmax(scores))])\n",
    "print('Silhouette por k:', dict(zip(k_opts, np.round(scores, 3))), '| melhor k =', best_k)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(k_opts, scores, marker='o')\n",
    "plt.title('Silhouette por número de clusters (k)')\n",
    "plt.xlabel('k'); plt.ylabel('Silhouette')\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / 'silhouette_k.png'); plt.show()\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "km = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "labels = km.fit_predict(X_scaled)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels, s=10)\n",
    "plt.title(f'Clusters (k={best_k}) em PCA 2D')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / 'clusters_pca.png'); plt.show()\n",
    "\n",
    "# Outliers (IsolationForest ~1%)\n",
    "iso = IsolationForest(random_state=42, contamination=0.01)\n",
    "anom = iso.fit_predict(X_scaled)  # -1 anômalo\n",
    "df['is_outlier'] = (anom == -1)\n",
    "print('Outliers detectados:', int(df['is_outlier'].sum()))\n",
    "display(df[df['is_outlier']][['crop', target] + num_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Modelagem Supervisionada (5 algoritmos) =====\n",
    "from math import sqrt\n",
    "\n",
    "X = df[cat_cols + num_cols]\n",
    "y = df[target]\n",
    "\n",
    "# Pré-processamento: OneHot(categorias) + Imputer/Scaler(numéricas)\n",
    "preprocess = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "    ('num', Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                      ('scaler', StandardScaler())]), num_cols)\n",
    "])\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=200, random_state=42),\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=300, learning_rate=0.1, max_depth=5,\n",
    "        subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n",
    "        random_state=42, objective='reg:squarederror', n_jobs=1\n",
    "    )\n",
    "}\n",
    "\n",
    "def evaluate_model(name, model):\n",
    "    pipe = Pipeline(steps=[('prep', preprocess), ('model', model)])\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)  # 3-fold p/ execução rápida\n",
    "    mae = -cross_val_score(pipe, X, y, scoring='neg_mean_absolute_error', cv=kf).mean()\n",
    "    rmse = np.sqrt(-cross_val_score(pipe, X, y, scoring='neg_mean_squared_error', cv=kf).mean())\n",
    "    r2 = cross_val_score(pipe, X, y, scoring='r2', cv=kf).mean()\n",
    "    return {'model': name, 'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "results = [evaluate_model(n, m) for n, m in models.items()]\n",
    "res_df = pd.DataFrame(results).sort_values('RMSE').reset_index(drop=True)\n",
    "display(res_df)\n",
    "\n",
    "# Gráficos simples\n",
    "plt.figure(); plt.bar(res_df['model'], res_df['RMSE']); plt.title('Comparação — RMSE (↓ melhor)'); plt.xlabel('Modelo'); plt.ylabel('RMSE'); plt.tight_layout(); plt.savefig(FIG_DIR / 'model_rmse.png'); plt.show()\n",
    "plt.figure(); plt.bar(res_df['model'], res_df['R2']); plt.title('Comparação — R² (↑ melhor)'); plt.xlabel('Modelo'); plt.ylabel('R²'); plt.tight_layout(); plt.savefig(FIG_DIR / 'model_r2.png'); plt.show()\n",
    "\n",
    "best_name = res_df.iloc[0]['model']\n",
    "best_model = models[best_name]\n",
    "best_pipe = Pipeline(steps=[('prep', preprocess), ('model', best_model)]).fit(X, y)\n",
    "joblib.dump(best_pipe, ART_DIR / 'best_model.joblib')\n",
    "print('Melhor modelo:', best_name, '| salvo em artifacts/best_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Demonstração de predição =====\n",
    "loaded = joblib.load(ART_DIR / 'best_model.joblib')\n",
    "\n",
    "# exemplo: usar a primeira linha como template e alterar valores\n",
    "ex = df.iloc[[0]][cat_cols + num_cols].copy()\n",
    "ex.loc[:, 'temp_c'] = ex['temp_c'].values + 1.0  # simular cenário mais quente\n",
    "pred = loaded.predict(ex)[0]\n",
    "print('Predição (t/ha) para o exemplo sintetizado:', round(float(pred), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab030e8",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusões\n",
    "- **Clusterização (KMeans)** evidenciou perfis de produtividade distintos; visualizamos em 2D via **PCA**.\n",
    "- **Outliers** (~1%) identificados por **IsolationForest** podem indicar leituras atípicas, erros de sensor ou microclimas.\n",
    "- Comparamos **Regressão Linear, Árvore de Decisão, KNN, RandomForest e XGBoost** com **MAE, RMSE e R²** usando *pipelines* e *cross-validation*.\n",
    "- O melhor modelo (ver tabela/gráficos) foi exportado para `artifacts/best_model.joblib`.\n",
    "\n",
    "**Próximos passos**\n",
    "- *TimeSeriesSplit* (se houver componente temporal), *tuning* de hiperparâmetros (Grid/Random/Bayes), novas features (sazonalidade, tipo de solo, latitude/longitude).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c5374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Apêndice: versões =====\n",
    "import sklearn, xgboost, platform\n",
    "print('Python:', platform.python_version())\n",
    "print('sklearn:', sklearn.__version__)\n",
    "print('xgboost:', xgboost.__version__)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
